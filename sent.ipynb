{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSSsoBWTV32iofPVTe2wRN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veerendra4923/Cam_Grey/blob/master/sent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htx4EJW7eBps",
        "outputId": "8605b28c-576a-498f-99ac-6f9a7a445c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=1164b83644447864e5020af3409b7e49eaf0868c12c5a8893aa0a555e3dcc478\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, feedparser, update_checker, prawcore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, praw, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed feedparser-6.0.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 praw-7.8.1 prawcore-2.4.0 sgmllib3k-1.0.0 update_checker-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch yfinance pandas feedparser praw requests numpy scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finbert_finetuning.py - Fine-tune FinBERT on Financial Sentiment Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "class FinancialSentimentDataset(Dataset):\n",
        "    \"\"\"Custom dataset for financial sentiment analysis\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class FinBERTTrainer:\n",
        "    \"\"\"FinBERT Fine-tuning class\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"ProsusAI/finbert\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def load_and_prepare_data(self, csv_file_path):\n",
        "        \"\"\"Load and prepare the financial sentiment dataset\"\"\"\n",
        "        print(\"üì• Loading dataset...\")\n",
        "\n",
        "        # Load the CSV file\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        print(f\"üìä Loaded {len(df)} samples\")\n",
        "\n",
        "        # Display dataset info\n",
        "        print(f\"\\nüìã Dataset Info:\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "\n",
        "        # Check for required columns\n",
        "        required_columns = ['text', 'label']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            print(f\"‚ùå Missing required columns. Expected: {required_columns}\")\n",
        "            print(f\"Available columns: {list(df.columns)}\")\n",
        "            return False\n",
        "\n",
        "        # Remove any rows with missing values\n",
        "        df = df.dropna(subset=['text', 'label'])\n",
        "        print(f\"üìä After removing NaN: {len(df)} samples\")\n",
        "\n",
        "        # Display label distribution\n",
        "        print(f\"\\nüìä Label Distribution:\")\n",
        "        label_counts = df['label'].value_counts()\n",
        "        print(label_counts)\n",
        "\n",
        "        # Map labels to integers\n",
        "        label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "        df['label_encoded'] = df['label'].map(label_mapping)\n",
        "\n",
        "        # Check for unmapped labels\n",
        "        unmapped = df[df['label_encoded'].isna()]\n",
        "        if len(unmapped) > 0:\n",
        "            print(f\"‚ö†Ô∏è Found {len(unmapped)} unmapped labels:\")\n",
        "            print(unmapped['label'].unique())\n",
        "            df = df.dropna(subset=['label_encoded'])\n",
        "            print(f\"üìä After removing unmapped labels: {len(df)} samples\")\n",
        "\n",
        "        # Extract texts and labels\n",
        "        texts = df['text'].tolist()\n",
        "        labels = df['label_encoded'].astype(int).tolist()\n",
        "\n",
        "        # Split data\n",
        "        print(f\"\\nüîÑ Splitting data...\")\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"üìä Train: {len(X_train)} samples\")\n",
        "        print(f\"üìä Validation: {len(X_val)} samples\")\n",
        "        print(f\"üìä Test: {len(X_test)} samples\")\n",
        "\n",
        "        # Store splits\n",
        "        self.X_train, self.y_train = X_train, y_train\n",
        "        self.X_val, self.y_val = X_val, y_val\n",
        "        self.X_test, self.y_test = X_test, y_test\n",
        "        self.label_mapping = label_mapping\n",
        "        self.reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "\n",
        "        return True\n",
        "\n",
        "    def prepare_model_and_tokenizer(self):\n",
        "        \"\"\"Initialize FinBERT model and tokenizer\"\"\"\n",
        "        print(f\"\\nü§ñ Loading FinBERT model: {self.model_name}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        # Load model for sequence classification\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            self.model_name,\n",
        "            num_labels=3,  # negative, neutral, positive\n",
        "            problem_type=\"single_label_classification\"\n",
        "        )\n",
        "\n",
        "        # Move to device\n",
        "        self.model.to(device)\n",
        "\n",
        "        print(\"‚úÖ Model and tokenizer loaded successfully!\")\n",
        "\n",
        "    def create_datasets(self, max_length=512):\n",
        "        \"\"\"Create PyTorch datasets\"\"\"\n",
        "        print(f\"\\nüì¶ Creating datasets with max_length={max_length}...\")\n",
        "\n",
        "        self.train_dataset = FinancialSentimentDataset(\n",
        "            self.X_train, self.y_train, self.tokenizer, max_length\n",
        "        )\n",
        "\n",
        "        self.val_dataset = FinancialSentimentDataset(\n",
        "            self.X_val, self.y_val, self.tokenizer, max_length\n",
        "        )\n",
        "\n",
        "        self.test_dataset = FinancialSentimentDataset(\n",
        "            self.X_test, self.y_test, self.tokenizer, max_length\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Datasets created successfully!\")\n",
        "\n",
        "    def compute_metrics(self, eval_pred):\n",
        "        \"\"\"Compute metrics for evaluation\"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "        }\n",
        "\n",
        "    def train_model(self, output_dir=\"./finbert_financial_sentiment\",\n",
        "                   num_epochs=3, batch_size=16, learning_rate=2e-5):\n",
        "        \"\"\"Fine-tune the FinBERT model\"\"\"\n",
        "        print(f\"\\nüöÄ Starting fine-tuning...\")\n",
        "        print(f\"üìä Training parameters:\")\n",
        "        print(f\"   ‚Ä¢ Epochs: {num_epochs}\")\n",
        "        print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
        "        print(f\"   ‚Ä¢ Learning rate: {learning_rate}\")\n",
        "        print(f\"   ‚Ä¢ Output directory: {output_dir}\")\n",
        "\n",
        "        # Create output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Check transformers version and set appropriate parameters\n",
        "        import transformers\n",
        "        transformers_version = transformers.__version__\n",
        "        print(f\"üîß Transformers version: {transformers_version}\")\n",
        "\n",
        "        try:\n",
        "            # Try with newer parameter name first\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=output_dir,\n",
        "                num_train_epochs=num_epochs,\n",
        "                per_device_train_batch_size=batch_size,\n",
        "                per_device_eval_batch_size=batch_size,\n",
        "                warmup_steps=500,\n",
        "                weight_decay=0.01,\n",
        "                learning_rate=learning_rate,\n",
        "                logging_dir=f'{output_dir}/logs',\n",
        "                logging_steps=100,\n",
        "                eval_strategy=\"steps\",  # Updated parameter name\n",
        "                eval_steps=500,\n",
        "                save_strategy=\"steps\",\n",
        "                save_steps=500,\n",
        "                load_best_model_at_end=True,\n",
        "                metric_for_best_model=\"accuracy\",\n",
        "                greater_is_better=True,\n",
        "                report_to=None,  # Disable wandb/tensorboard\n",
        "                save_total_limit=2,\n",
        "                dataloader_pin_memory=False,  # For Colab compatibility\n",
        "            )\n",
        "            print(\"‚úÖ Using 'eval_strategy' parameter\")\n",
        "        except TypeError:\n",
        "            try:\n",
        "                # Fallback to older parameter name\n",
        "                training_args = TrainingArguments(\n",
        "                    output_dir=output_dir,\n",
        "                    num_train_epochs=num_epochs,\n",
        "                    per_device_train_batch_size=batch_size,\n",
        "                    per_device_eval_batch_size=batch_size,\n",
        "                    warmup_steps=500,\n",
        "                    weight_decay=0.01,\n",
        "                    learning_rate=learning_rate,\n",
        "                    logging_dir=f'{output_dir}/logs',\n",
        "                    logging_steps=100,\n",
        "                    evaluation_strategy=\"steps\",  # Older parameter name\n",
        "                    eval_steps=500,\n",
        "                    save_strategy=\"steps\",\n",
        "                    save_steps=500,\n",
        "                    load_best_model_at_end=True,\n",
        "                    metric_for_best_model=\"accuracy\",\n",
        "                    greater_is_better=True,\n",
        "                    report_to=None,  # Disable wandb/tensorboard\n",
        "                    save_total_limit=2,\n",
        "                    dataloader_pin_memory=False,  # For Colab compatibility\n",
        "                )\n",
        "                print(\"‚úÖ Using 'evaluation_strategy' parameter (older version)\")\n",
        "            except TypeError:\n",
        "                # Minimal configuration as last resort\n",
        "                training_args = TrainingArguments(\n",
        "                    output_dir=output_dir,\n",
        "                    num_train_epochs=num_epochs,\n",
        "                    per_device_train_batch_size=batch_size,\n",
        "                    per_device_eval_batch_size=batch_size,\n",
        "                    learning_rate=learning_rate,\n",
        "                    logging_steps=100,\n",
        "                    save_strategy=\"epoch\",\n",
        "                    load_best_model_at_end=True,\n",
        "                    report_to=None,\n",
        "                    save_total_limit=2,\n",
        "                    dataloader_pin_memory=False,\n",
        "                )\n",
        "                print(\"‚ö†Ô∏è Using minimal TrainingArguments configuration\")\n",
        "\n",
        "        # Create trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=self.train_dataset,\n",
        "            eval_dataset=self.val_dataset,\n",
        "            compute_metrics=self.compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "        )\n",
        "\n",
        "        # Start training\n",
        "        print(\"üèãÔ∏è Training started...\")\n",
        "        train_result = trainer.train()\n",
        "\n",
        "        # Save the fine-tuned model\n",
        "        print(f\"\\nüíæ Saving fine-tuned model to {output_dir}...\")\n",
        "        trainer.save_model()\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Save training info\n",
        "        training_info = {\n",
        "            'model_name': self.model_name,\n",
        "            'num_epochs': num_epochs,\n",
        "            'batch_size': batch_size,\n",
        "            'learning_rate': learning_rate,\n",
        "            'train_samples': len(self.X_train),\n",
        "            'val_samples': len(self.X_val),\n",
        "            'test_samples': len(self.X_test),\n",
        "            'label_mapping': self.label_mapping,\n",
        "            'training_time': str(datetime.now()),\n",
        "            'train_loss': train_result.training_loss,\n",
        "            'transformers_version': transformers_version,\n",
        "        }\n",
        "\n",
        "        with open(f'{output_dir}/training_info.json', 'w') as f:\n",
        "            json.dump(training_info, f, indent=2)\n",
        "\n",
        "        print(\"‚úÖ Model saved successfully!\")\n",
        "        return trainer\n",
        "\n",
        "    def evaluate_model(self, trainer, output_dir=\"./finbert_financial_sentiment\"):\n",
        "        \"\"\"Evaluate the fine-tuned model\"\"\"\n",
        "        print(f\"\\nüìä Evaluating model...\")\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_results = trainer.evaluate()\n",
        "        print(f\"üìä Validation Results:\")\n",
        "        for key, value in val_results.items():\n",
        "            print(f\"   ‚Ä¢ {key}: {value:.4f}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_results = trainer.evaluate(self.test_dataset)\n",
        "        print(f\"\\nüìä Test Results:\")\n",
        "        for key, value in test_results.items():\n",
        "            print(f\"   ‚Ä¢ {key}: {value:.4f}\")\n",
        "\n",
        "        # Generate detailed predictions for test set\n",
        "        predictions = trainer.predict(self.test_dataset)\n",
        "        y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "        y_true = self.y_test\n",
        "\n",
        "        # Calculate detailed metrics\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        print(f\"\\nüìä Detailed Test Metrics:\")\n",
        "        print(f\"   ‚Ä¢ Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        # Classification report\n",
        "        target_names = [self.reverse_label_mapping[i] for i in range(3)]\n",
        "        report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "        print(f\"\\nüìã Classification Report:\")\n",
        "        print(report)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=target_names, yticklabels=target_names)\n",
        "        plt.title('Confusion Matrix - Fine-tuned FinBERT')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{output_dir}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Save evaluation results\n",
        "        eval_results = {\n",
        "            'val_accuracy': val_results.get('eval_accuracy', 0),\n",
        "            'test_accuracy': accuracy,\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm.tolist(),\n",
        "        }\n",
        "\n",
        "        with open(f'{output_dir}/evaluation_results.json', 'w') as f:\n",
        "            json.dump(eval_results, f, indent=2)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def test_sample_predictions(self, output_dir=\"./finbert_financial_sentiment\", num_samples=10):\n",
        "        \"\"\"Test model with sample predictions\"\"\"\n",
        "        print(f\"\\nüß™ Testing sample predictions...\")\n",
        "\n",
        "        # Load the saved model for testing\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Sample some test examples\n",
        "        sample_indices = np.random.choice(len(self.X_test), min(num_samples, len(self.X_test)), replace=False)\n",
        "\n",
        "        print(f\"\\nüìã Sample Predictions:\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        for i, idx in enumerate(sample_indices):\n",
        "            text = self.X_test[idx]\n",
        "            true_label = self.reverse_label_mapping[self.y_test[idx]]\n",
        "\n",
        "            # Make prediction\n",
        "            inputs = tokenizer(text, return_tensors='pt', truncation=True,\n",
        "                             padding=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "                predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "                confidence = torch.max(predictions).item()\n",
        "\n",
        "            predicted_label = self.reverse_label_mapping[predicted_class]\n",
        "\n",
        "            print(f\"\\nüîç Sample {i+1}:\")\n",
        "            print(f\"Text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
        "            print(f\"True: {true_label}\")\n",
        "            print(f\"Predicted: {predicted_label} (confidence: {confidence:.3f})\")\n",
        "            print(f\"Correct: {'‚úÖ' if true_label == predicted_label else '‚ùå'}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "def load_dataset(file_path=\"final_merged_financial_sentiment_dataset.csv\"):\n",
        "    \"\"\"Load the financial sentiment dataset\"\"\"\n",
        "    print(f\"üì• Loading dataset from: {file_path}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "        print(f\"üìä Shape: {df.shape}\")\n",
        "        print(f\"üìã Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Display first few rows\n",
        "        print(f\"\\nüìã First 5 rows:\")\n",
        "        print(df.head())\n",
        "\n",
        "        # Check data quality\n",
        "        print(f\"\\nüîç Data Quality Check:\")\n",
        "        print(f\"Missing values in 'text': {df['text'].isna().sum()}\")\n",
        "        print(f\"Missing values in 'label': {df['label'].isna().sum()}\")\n",
        "\n",
        "        # Label distribution\n",
        "        print(f\"\\nüìä Label Distribution:\")\n",
        "        print(df['label'].value_counts())\n",
        "\n",
        "        return df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå File not found: {file_path}\")\n",
        "        print(\"Please ensure the CSV file is in the correct location.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main fine-tuning pipeline\"\"\"\n",
        "    print(\"üöÄ FINBERT FINE-TUNING FOR FINANCIAL SENTIMENT ANALYSIS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Configuration\n",
        "    CSV_FILE_PATH = \"final_merged_financial_sentiment_dataset.csv\"\n",
        "    OUTPUT_DIR = \"./finbert_financial_sentiment\"\n",
        "\n",
        "    print(f\"üìã Configuration:\")\n",
        "    print(f\"   ‚Ä¢ Dataset: {CSV_FILE_PATH}\")\n",
        "    print(f\"   ‚Ä¢ Output Directory: {OUTPUT_DIR}\")\n",
        "    print(f\"   ‚Ä¢ Device: {device}\")\n",
        "\n",
        "    # Load dataset\n",
        "    df = load_dataset(CSV_FILE_PATH)\n",
        "    if df is None:\n",
        "        return\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = FinBERTTrainer()\n",
        "\n",
        "    # Load and prepare data\n",
        "    if not trainer.load_and_prepare_data(CSV_FILE_PATH):\n",
        "        return\n",
        "\n",
        "    # Prepare model and tokenizer\n",
        "    trainer.prepare_model_and_tokenizer()\n",
        "\n",
        "    # Create datasets\n",
        "    trainer.create_datasets()\n",
        "\n",
        "    # Get training parameters from user\n",
        "    print(f\"\\n‚öôÔ∏è Training Parameters:\")\n",
        "\n",
        "    try:\n",
        "        epochs = int(input(\"Enter number of epochs (default: 3): \") or \"3\")\n",
        "        batch_size = int(input(\"Enter batch size (default: 16): \") or \"16\")\n",
        "        learning_rate = float(input(\"Enter learning rate (default: 2e-5): \") or \"2e-5\")\n",
        "    except ValueError:\n",
        "        print(\"Using default parameters...\")\n",
        "        epochs = 3\n",
        "        batch_size = 16\n",
        "        learning_rate = 2e-5\n",
        "\n",
        "    print(f\"\\nüèãÔ∏è Starting training with:\")\n",
        "    print(f\"   ‚Ä¢ Epochs: {epochs}\")\n",
        "    print(f\"   ‚Ä¢ Batch size: {batch_size}\")\n",
        "    print(f\"   ‚Ä¢ Learning rate: {learning_rate}\")\n",
        "\n",
        "    # Train model\n",
        "    trainer_obj = trainer.train_model(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    accuracy = trainer.evaluate_model(trainer_obj, OUTPUT_DIR)\n",
        "\n",
        "    # Test sample predictions\n",
        "    trainer.test_sample_predictions(OUTPUT_DIR)\n",
        "\n",
        "    # Create download script for Colab\n",
        "    create_download_script(OUTPUT_DIR, accuracy)\n",
        "\n",
        "    print(f\"\\nüéâ Fine-tuning completed successfully!\")\n",
        "    print(f\"üìä Final test accuracy: {accuracy:.4f}\")\n",
        "    print(f\"üíæ Model saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "def create_download_script(output_dir, accuracy):\n",
        "    \"\"\"Create a script to download the model in Colab\"\"\"\n",
        "    download_script = f\"\"\"\n",
        "# Download Fine-tuned FinBERT Model - Run this in a new cell\n",
        "import zipfile\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def download_finetuned_model():\n",
        "    model_dir = \"{output_dir}\"\n",
        "    zip_filename = \"finbert_financial_sentiment_model.zip\"\n",
        "\n",
        "    print(\"üì¶ Creating zip file...\")\n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(model_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Add file to zip with relative path\n",
        "                zipf.write(file_path, os.path.relpath(file_path, os.path.dirname(model_dir)))\n",
        "\n",
        "    print(f\"‚úÖ Model zipped successfully!\")\n",
        "    print(f\"üìä Model accuracy: {accuracy:.4f}\")\n",
        "    print(f\"üì• Downloading {{zip_filename}}...\")\n",
        "\n",
        "    # Download the zip file\n",
        "    files.download(zip_filename)\n",
        "\n",
        "    print(\"‚úÖ Download complete!\")\n",
        "    print(\"\\\\nüìã To use this model:\")\n",
        "    print(\"1. Extract the zip file\")\n",
        "    print(\"2. Place the 'finbert_financial_sentiment' folder in your project\")\n",
        "    print(\"3. Update the model_path in your sentiment analysis script\")\n",
        "\n",
        "# Run the download\n",
        "download_finetuned_model()\n",
        "\"\"\"\n",
        "\n",
        "    with open(\"download_model.py\", \"w\") as f:\n",
        "        f.write(download_script)\n",
        "\n",
        "    print(f\"\\nüì• Download script created: download_model.py\")\n",
        "    print(\"Run this script in a new Colab cell to download your fine-tuned model!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EbvHoguWxkwJ",
        "outputId": "143eb856-12ef-484b-898f-258f6156512e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Using device: cuda\n",
            "üöÄ FINBERT FINE-TUNING FOR FINANCIAL SENTIMENT ANALYSIS\n",
            "======================================================================\n",
            "üìã Configuration:\n",
            "   ‚Ä¢ Dataset: final_merged_financial_sentiment_dataset.csv\n",
            "   ‚Ä¢ Output Directory: ./finbert_financial_sentiment\n",
            "   ‚Ä¢ Device: cuda\n",
            "üì• Loading dataset from: final_merged_financial_sentiment_dataset.csv\n",
            "‚úÖ Dataset loaded successfully!\n",
            "üìä Shape: (2302, 3)\n",
            "üìã Columns: ['text', 'label', 'source']\n",
            "\n",
            "üìã First 5 rows:\n",
            "                                                text     label  \\\n",
            "0  According to Gran , the company has no plans t...   neutral   \n",
            "1  For the last quarter of 2010 , Componenta 's n...  positive   \n",
            "2  In the third quarter of 2010 , net sales incre...  positive   \n",
            "3  Operating profit rose to EUR 13.1 mn from EUR ...  positive   \n",
            "4  Operating profit totalled EUR 21.1 mn , up fro...  positive   \n",
            "\n",
            "                source  \n",
            "0  PhraseBank_AllAgree  \n",
            "1  PhraseBank_AllAgree  \n",
            "2  PhraseBank_AllAgree  \n",
            "3  PhraseBank_AllAgree  \n",
            "4  PhraseBank_AllAgree  \n",
            "\n",
            "üîç Data Quality Check:\n",
            "Missing values in 'text': 0\n",
            "Missing values in 'label': 0\n",
            "\n",
            "üìä Label Distribution:\n",
            "label\n",
            "neutral     1402\n",
            "positive     590\n",
            "negative     310\n",
            "Name: count, dtype: int64\n",
            "üì• Loading dataset...\n",
            "üìä Loaded 2302 samples\n",
            "\n",
            "üìã Dataset Info:\n",
            "Columns: ['text', 'label', 'source']\n",
            "Shape: (2302, 3)\n",
            "üìä After removing NaN: 2302 samples\n",
            "\n",
            "üìä Label Distribution:\n",
            "label\n",
            "neutral     1402\n",
            "positive     590\n",
            "negative     310\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üîÑ Splitting data...\n",
            "üìä Train: 1472 samples\n",
            "üìä Validation: 369 samples\n",
            "üìä Test: 461 samples\n",
            "\n",
            "ü§ñ Loading FinBERT model: ProsusAI/finbert\n",
            "‚úÖ Model and tokenizer loaded successfully!\n",
            "\n",
            "üì¶ Creating datasets with max_length=512...\n",
            "‚úÖ Datasets created successfully!\n",
            "\n",
            "‚öôÔ∏è Training Parameters:\n",
            "Enter number of epochs (default: 3): 3\n",
            "Enter batch size (default: 16): 16\n",
            "Enter learning rate (default: 2e-5): 2e-5\n",
            "\n",
            "üèãÔ∏è Starting training with:\n",
            "   ‚Ä¢ Epochs: 3\n",
            "   ‚Ä¢ Batch size: 16\n",
            "   ‚Ä¢ Learning rate: 2e-05\n",
            "\n",
            "üöÄ Starting fine-tuning...\n",
            "üìä Training parameters:\n",
            "   ‚Ä¢ Epochs: 3\n",
            "   ‚Ä¢ Batch size: 16\n",
            "   ‚Ä¢ Learning rate: 2e-05\n",
            "   ‚Ä¢ Output directory: ./finbert_financial_sentiment\n",
            "üîß Transformers version: 4.54.0\n",
            "‚úÖ Using 'eval_strategy' parameter\n",
            "üèãÔ∏è Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [276/276 06:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Saving fine-tuned model to ./finbert_financial_sentiment...\n",
            "‚úÖ Model saved successfully!\n",
            "\n",
            "üìä Evaluating model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Validation Results:\n",
            "   ‚Ä¢ eval_loss: 0.1438\n",
            "   ‚Ä¢ eval_accuracy: 0.9485\n",
            "   ‚Ä¢ eval_runtime: 11.0758\n",
            "   ‚Ä¢ eval_samples_per_second: 33.3160\n",
            "   ‚Ä¢ eval_steps_per_second: 2.1670\n",
            "   ‚Ä¢ epoch: 3.0000\n",
            "\n",
            "üìä Test Results:\n",
            "   ‚Ä¢ eval_loss: 0.1331\n",
            "   ‚Ä¢ eval_accuracy: 0.9436\n",
            "   ‚Ä¢ eval_runtime: 14.2643\n",
            "   ‚Ä¢ eval_samples_per_second: 32.3190\n",
            "   ‚Ä¢ eval_steps_per_second: 2.0330\n",
            "   ‚Ä¢ epoch: 3.0000\n",
            "\n",
            "üìä Detailed Test Metrics:\n",
            "   ‚Ä¢ Accuracy: 0.9436\n",
            "\n",
            "üìã Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.92      0.86        62\n",
            "     neutral       0.98      0.99      0.98       281\n",
            "    positive       0.94      0.86      0.89       118\n",
            "\n",
            "    accuracy                           0.94       461\n",
            "   macro avg       0.91      0.92      0.91       461\n",
            "weighted avg       0.95      0.94      0.94       461\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing sample predictions...\n",
            "\n",
            "üìã Sample Predictions:\n",
            "================================================================================\n",
            "\n",
            "üîç Sample 1:\n",
            "Text: Cash flow from operations in January-December 2008 was a negative EUR 18.1 mn compared to EUR 39.0 m...\n",
            "True: negative\n",
            "Predicted: negative (confidence: 0.937)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 2:\n",
            "Text: Nordstjernan has used its option to buy another 22.4 % stake of Salcomp 's shares and votes .\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.887)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 3:\n",
            "Text: Our key geographical markets are Europe , Russian Federation , Middle-East , South-Africa and Japan ...\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.980)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 4:\n",
            "Text: 25 November 2010 - Finnish paints and coatings company Tikkurila Oyj ( HEL : TIK1V ) said today that...\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.941)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 5:\n",
            "Text: Affecto has participated in the program for the development of the Norwegian pension system since 20...\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.979)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 6:\n",
            "Text: Cargotec Corporation , Press Release , August 26 , 2008 at 10 a.m. Finnish time Cargotec 's MacGREGO...\n",
            "True: positive\n",
            "Predicted: neutral (confidence: 0.865)\n",
            "Correct: ‚ùå\n",
            "\n",
            "üîç Sample 7:\n",
            "Text: The company said that the results of the third quarter do not include non-recurring items .\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.984)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 8:\n",
            "Text: Established in 1989 , CapMan manages Nordic buyout , mezzanine , technology , life science and real ...\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.982)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 9:\n",
            "Text: The company 's operating income ( EBIT ) totalled EUR 0.0 mn , up from EUR -0.3 mn year-on-year .\n",
            "True: positive\n",
            "Predicted: positive (confidence: 0.971)\n",
            "Correct: ‚úÖ\n",
            "\n",
            "üîç Sample 10:\n",
            "Text: The company also appointed Leif Rosen head of the Special Plate unit which includes the quarto plate...\n",
            "True: neutral\n",
            "Predicted: neutral (confidence: 0.985)\n",
            "Correct: ‚úÖ\n",
            "================================================================================\n",
            "\n",
            "üì• Download script created: download_model.py\n",
            "Run this script in a new Colab cell to download your fine-tuned model!\n",
            "\n",
            "üéâ Fine-tuning completed successfully!\n",
            "üìä Final test accuracy: 0.9436\n",
            "üíæ Model saved to: ./finbert_financial_sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Save your training accuracy\n",
        "training_info = {\n",
        "    \"test_accuracy\": 0.9436,\n",
        "    \"test_accuracy_percentage\": \"94.36%\",\n",
        "    \"model_type\": \"fine_tuned_finbert_financial\",\n",
        "    \"performance_rating\": \"excellent\"\n",
        "}\n",
        "\n",
        "# Save to model directory\n",
        "with open(\"./finbert_financial_sentiment/training_info.json\", 'w') as f:\n",
        "    json.dump(training_info, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Training info saved! Accuracy will now display correctly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJgi_jeD-VQe",
        "outputId": "73d952b1-66aa-4718-a1d3-108e57740d67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training info saved! Accuracy will now display correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# financial_sentiment_analysis.py - Complete Sentiment Analysis with Fine-tuned FinBERT on Financial Data\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import time\n",
        "import warnings\n",
        "import os\n",
        "import logging\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Try to import optional libraries\n",
        "try:\n",
        "    import feedparser\n",
        "    HAS_FEEDPARSER = True\n",
        "except ImportError:\n",
        "    HAS_FEEDPARSER = False\n",
        "    print(\"‚ö†Ô∏è feedparser not installed. GNews and RSS feeds will be unavailable.\")\n",
        "\n",
        "try:\n",
        "    import praw\n",
        "    HAS_REDDIT = True\n",
        "except ImportError:\n",
        "    HAS_REDDIT = False\n",
        "    print(\"‚ö†Ô∏è praw not installed. Reddit data will be unavailable.\")\n",
        "\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "    import torch\n",
        "    HAS_TRANSFORMERS = True\n",
        "except ImportError:\n",
        "    HAS_TRANSFORMERS = False\n",
        "    print(\"‚ö†Ô∏è transformers not installed. Fine-tuned FinBERT will be unavailable.\")\n",
        "\n",
        "try:\n",
        "    import yfinance as yf\n",
        "    import pandas as pd\n",
        "    HAS_YFINANCE = True\n",
        "except ImportError:\n",
        "    HAS_YFINANCE = False\n",
        "    print(\"‚ö†Ô∏è yfinance not installed. Stock market data snapshot will be unavailable.\")\n",
        "\n",
        "# API Configuration - Using environment variables or None\n",
        "def get_api_key(key_name: str) -> Optional[str]:\n",
        "    \"\"\"Safely get API keys from environment or return None\"\"\"\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        return userdata.get(key_name)\n",
        "    except:\n",
        "        return os.environ.get(key_name)\n",
        "\n",
        "API_KEYS = {\n",
        "    \"REDDIT_CLIENT_ID\": get_api_key('reddit_client_id'),\n",
        "    \"REDDIT_CLIENT_SECRET\": get_api_key('reddit_client_secret'),\n",
        "    \"REDDIT_USER_AGENT\": \"windows:FINANCIAL_SENTIMENT:1.0 (by u/FinancialAnalyst)\",\n",
        "    \"YOUTUBE_API_KEY\": get_api_key('YOUTUBE_API_KEY'),\n",
        "    \"TWITTER_BEARER_TOKEN\": get_api_key('twitter_api'),\n",
        "    \"ALPHA_VANTAGE_API_KEY\": get_api_key('alpha_vantage'),\n",
        "    \"NEWS_API_KEY\": get_api_key('news_api'),\n",
        "}\n",
        "\n",
        "class FinancialFinBERTAnalyzer:\n",
        "    \"\"\"Fine-tuned FinBERT sentiment analyzer trained on financial data\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"./finbert_financial_sentiment\"):\n",
        "        self.model_path = model_path\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") if HAS_TRANSFORMERS else None\n",
        "        self.label_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "        self.training_accuracy = \"Unknown\"\n",
        "\n",
        "        print(f\"üöÄ Initializing Financial Fine-tuned FinBERT model...\")\n",
        "        print(f\"üìç Model path: {model_path}\")\n",
        "        if self.device:\n",
        "            print(f\"üîß Using device: {self.device}\")\n",
        "\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the fine-tuned financial sentiment model\"\"\"\n",
        "        if not HAS_TRANSFORMERS:\n",
        "            print(\"‚ùå transformers library not available - using fallback sentiment analysis\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(self.model_path):\n",
        "            print(f\"‚ùå Model path not found: {self.model_path}\")\n",
        "            print(\"Please ensure your fine-tuned financial model is in the correct location.\")\n",
        "            print(\"Run the fine-tuning script first to create the model.\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(\"üì• Loading tokenizer...\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
        "\n",
        "            print(\"üì• Loading fine-tuned financial model...\")\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                self.model_path,\n",
        "                num_labels=3  # negative, neutral, positive\n",
        "            )\n",
        "\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            # Load training info if available\n",
        "            info_path = os.path.join(self.model_path, 'training_info.json')\n",
        "            if os.path.exists(info_path):\n",
        "                try:\n",
        "                    with open(info_path, 'r') as f:\n",
        "                        training_info = json.load(f)\n",
        "                        self.training_accuracy = training_info.get('test_accuracy', 'Unknown')\n",
        "                        print(f\"üìä Model training accuracy: {self.training_accuracy}\")\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Could not load training info: {e}\")\n",
        "\n",
        "            print(\"‚úÖ Financial Fine-tuned FinBERT model loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading fine-tuned model: {e}\")\n",
        "            print(\"Make sure your model files are correctly saved and accessible.\")\n",
        "            self.model = None\n",
        "            self.tokenizer = None\n",
        "\n",
        "    def predict_sentiment(self, text: str) -> Dict:\n",
        "        \"\"\"Predict sentiment using fine-tuned financial model\"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            return self._basic_sentiment_fallback(text)\n",
        "\n",
        "        if not text or len(text.strip()) < 5:\n",
        "            return {\"sentiment\": 0.0, \"confidence\": 0.0, \"label\": \"neutral\", \"method\": \"empty_text\"}\n",
        "\n",
        "        try:\n",
        "            # Preprocess text\n",
        "            clean_text = self._preprocess_text(text)\n",
        "\n",
        "            # Tokenize input\n",
        "            inputs = self.tokenizer(\n",
        "                clean_text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=512\n",
        "            )\n",
        "\n",
        "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Make prediction\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "            # Get results\n",
        "            predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "            confidence = torch.max(predictions).item()\n",
        "\n",
        "            # Get all class probabilities\n",
        "            probs = predictions.cpu().numpy()[0]\n",
        "\n",
        "            # Convert to sentiment score (-1 to +1 scale)\n",
        "            if predicted_class == 2:  # positive\n",
        "                sentiment_score = probs[2] - probs[0]  # positive_prob - negative_prob\n",
        "            elif predicted_class == 0:  # negative\n",
        "                sentiment_score = -(probs[0] - probs[2])  # -(negative_prob - positive_prob)\n",
        "            else:  # neutral\n",
        "                sentiment_score = (probs[2] - probs[0]) * 0.5  # Muted sentiment for neutral\n",
        "\n",
        "            label = self.label_mapping[predicted_class]\n",
        "\n",
        "            return {\n",
        "                \"sentiment\": round(sentiment_score, 4),\n",
        "                \"confidence\": round(confidence, 4),\n",
        "                \"label\": label.upper(),\n",
        "                \"method\": \"fine_tuned_financial_finbert\",\n",
        "                \"predicted_class\": predicted_class,\n",
        "                \"class_probabilities\": {\n",
        "                    \"negative\": round(probs[0], 4),\n",
        "                    \"neutral\": round(probs[1], 4),\n",
        "                    \"positive\": round(probs[2], 4)\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fine-tuned model prediction error: {e}\")\n",
        "            return self._basic_sentiment_fallback(text)\n",
        "\n",
        "    def _preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and preprocess text for financial analysis\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Remove URLs\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "        # Preserve financial symbols and numbers\n",
        "        # Keep $ symbols, percentages, and stock tickers\n",
        "        text = re.sub(r'[^\\w\\s.,!?$%-]', '', text)\n",
        "\n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "    def _basic_sentiment_fallback(self, text: str) -> Dict:\n",
        "        \"\"\"Enhanced fallback sentiment analysis for financial text\"\"\"\n",
        "        if not text:\n",
        "            return {\"sentiment\": 0.0, \"confidence\": 0.0, \"label\": \"NEUTRAL\", \"method\": \"fallback_empty\"}\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Enhanced financial sentiment keywords\n",
        "        positive_words = [\n",
        "            'buy', 'bull', 'bullish', 'up', 'rise', 'rising', 'gain', 'gains',\n",
        "            'profit', 'profits', 'good', 'great', 'excellent', 'strong', 'growth',\n",
        "            'increase', 'positive', 'optimistic', 'confidence', 'outperform',\n",
        "            'beat', 'exceed', 'upgrade', 'recommend', 'target', 'momentum',\n",
        "            'rally', 'surge', 'boom', 'expansion', 'breakthrough', 'success',\n",
        "            'solid', 'robust', 'healthy', 'promising', 'favorable', 'dividend',\n",
        "            'earnings beat', 'revenue growth', 'market share', 'innovation'\n",
        "        ]\n",
        "\n",
        "        negative_words = [\n",
        "            'sell', 'bear', 'bearish', 'down', 'fall', 'falling', 'loss', 'losses',\n",
        "            'bad', 'terrible', 'weak', 'decline', 'decrease', 'negative',\n",
        "            'pessimistic', 'concern', 'underperform', 'miss', 'downgrade',\n",
        "            'avoid', 'risk', 'crash', 'drop', 'plunge', 'collapse',\n",
        "            'recession', 'crisis', 'warning', 'caution', 'debt', 'bankruptcy',\n",
        "            'lawsuit', 'fraud', 'scandal', 'volatility', 'uncertainty'\n",
        "        ]\n",
        "\n",
        "        neutral_words = [\n",
        "            'hold', 'neutral', 'stable', 'maintain', 'unchanged', 'steady',\n",
        "            'sideways', 'range', 'consolidation', 'wait', 'monitor'\n",
        "        ]\n",
        "\n",
        "        # Count occurrences\n",
        "        positive_count = sum(1 for word in positive_words if word in text_lower)\n",
        "        negative_count = sum(1 for word in negative_words if word in text_lower)\n",
        "        neutral_count = sum(1 for word in neutral_words if word in text_lower)\n",
        "\n",
        "        total_words = len(text.split())\n",
        "        if total_words == 0:\n",
        "            return {\"sentiment\": 0.0, \"confidence\": 0.0, \"label\": \"NEUTRAL\", \"method\": \"fallback_empty\"}\n",
        "\n",
        "        # Calculate sentiment score\n",
        "        net_sentiment = positive_count - negative_count\n",
        "        sentiment_raw = net_sentiment / max(total_words, 1)\n",
        "        sentiment_score = max(-1.0, min(1.0, sentiment_raw * 3))  # Scale and clamp\n",
        "\n",
        "        # Adjust for neutral words\n",
        "        if neutral_count > 0:\n",
        "            sentiment_score *= (1 - (neutral_count / max(total_words, 1)) * 0.5)\n",
        "\n",
        "        # Determine label and confidence\n",
        "        if sentiment_score > 0.15:\n",
        "            label = \"POSITIVE\"\n",
        "            confidence = min(0.8, abs(sentiment_score) + 0.4)\n",
        "        elif sentiment_score < -0.15:\n",
        "            label = \"NEGATIVE\"\n",
        "            confidence = min(0.8, abs(sentiment_score) + 0.4)\n",
        "        else:\n",
        "            label = \"NEUTRAL\"\n",
        "            confidence = 0.6\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": round(sentiment_score, 4),\n",
        "            \"confidence\": round(confidence, 4),\n",
        "            \"label\": label,\n",
        "            \"method\": \"enhanced_financial_fallback\"\n",
        "        }\n",
        "\n",
        "class FinancialDataCollector:\n",
        "    \"\"\"Enhanced data collector for financial sentiment analysis\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"./finbert_financial_sentiment\"):\n",
        "        self.sentiment_analyzer = FinancialFinBERTAnalyzer(model_path)\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        })\n",
        "\n",
        "        # Initialize Reddit client\n",
        "        self.reddit_client = None\n",
        "        if HAS_REDDIT and API_KEYS[\"REDDIT_CLIENT_ID\"] and API_KEYS[\"REDDIT_CLIENT_SECRET\"]:\n",
        "            try:\n",
        "                self.reddit_client = praw.Reddit(\n",
        "                    client_id=API_KEYS[\"REDDIT_CLIENT_ID\"],\n",
        "                    client_secret=API_KEYS[\"REDDIT_CLIENT_SECRET\"],\n",
        "                    user_agent=API_KEYS[\"REDDIT_USER_AGENT\"]\n",
        "                )\n",
        "                print(\"‚úÖ Reddit client initialized\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error initializing Reddit client: {e}\")\n",
        "                self.reddit_client = None\n",
        "\n",
        "    def _normalize_symbol(self, symbol: str) -> Dict[str, str]:\n",
        "        \"\"\"Extract and normalize symbol information\"\"\"\n",
        "        symbol = symbol.upper().strip()\n",
        "\n",
        "        # Handle different exchange formats\n",
        "        if symbol.endswith('.NS') or symbol.endswith('.BO'):\n",
        "            base_symbol = symbol.split('.')[0]\n",
        "            exchange = 'NSE' if symbol.endswith('.NS') else 'BSE'\n",
        "        elif symbol.endswith('.L'):\n",
        "            base_symbol = symbol.split('.')[0]\n",
        "            exchange = 'LSE'\n",
        "        else:\n",
        "            base_symbol = symbol\n",
        "            exchange = 'US'\n",
        "\n",
        "        # Get company information\n",
        "        company_name = \"\"\n",
        "        company_sector = \"\"\n",
        "\n",
        "        if HAS_YFINANCE:\n",
        "            try:\n",
        "                ticker_obj = yf.Ticker(symbol)\n",
        "                info = ticker_obj.info\n",
        "\n",
        "                company_name = info.get('longName', '')\n",
        "                if company_name:\n",
        "                    company_name = re.sub(r'\\b(Ltd|Limited|Inc|Corp|Corporation|Company|Co)\\b\\.?', '', company_name, flags=re.IGNORECASE)\n",
        "                    company_name = company_name.strip()\n",
        "\n",
        "                company_sector = info.get('sector', '')\n",
        "\n",
        "                print(f\"   üìã Company: {company_name}\")\n",
        "                print(f\"   üè¢ Sector: {company_sector}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è Could not retrieve company info: {e}\")\n",
        "\n",
        "        return {\n",
        "            'original_symbol': symbol,\n",
        "            'base_symbol': base_symbol,\n",
        "            'exchange': exchange,\n",
        "            'company_name': company_name,\n",
        "            'company_sector': company_sector\n",
        "        }\n",
        "\n",
        "    def get_reddit_sentiment(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get Reddit sentiment analysis\"\"\"\n",
        "        print(f\"üîç Fetching Reddit data for {symbol}...\")\n",
        "\n",
        "        if not HAS_REDDIT or not self.reddit_client:\n",
        "            print(\"‚ùå Reddit API not available - using demo data\")\n",
        "            symbol_info = self._normalize_symbol(symbol)\n",
        "            demo_texts = [\n",
        "                f\"{symbol} quarterly results exceeded expectations, strong fundamentals\",\n",
        "                f\"Bullish on {symbol}, technical analysis shows upward momentum\",\n",
        "                f\"{symbol} dividend announcement positively received by market\",\n",
        "                f\"Concerned about {symbol} debt levels, might affect future growth\",\n",
        "                f\"{symbol} management guidance looks promising for next quarter\",\n",
        "                f\"Institutional buying in {symbol} suggests confidence\",\n",
        "                f\"{symbol} sector rotation benefiting the stock significantly\"\n",
        "            ]\n",
        "            return self._analyze_texts(demo_texts, \"Reddit (Demo)\")\n",
        "\n",
        "        symbol_info = self._normalize_symbol(symbol)\n",
        "        texts = []\n",
        "\n",
        "        # Define subreddits based on exchange\n",
        "        if symbol_info['exchange'] in ['NSE', 'BSE']:\n",
        "            subreddits = ['IndiaInvestments', 'investing', 'stocks', 'SecurityAnalysis', 'IndianStreetBets']\n",
        "        else:\n",
        "            subreddits = ['investing', 'stocks', 'SecurityAnalysis', 'StockMarket', 'wallstreetbets']\n",
        "\n",
        "        # Search strategies\n",
        "        search_queries = [symbol_info['base_symbol']]\n",
        "        if symbol_info['company_name']:\n",
        "            search_queries.append(f'\"{symbol_info[\"company_name\"]}\"')\n",
        "\n",
        "        for query in search_queries[:2]:\n",
        "            for subreddit_name in subreddits:\n",
        "                if len(texts) >= 50:\n",
        "                    break\n",
        "\n",
        "                try:\n",
        "                    subreddit = self.reddit_client.subreddit(subreddit_name)\n",
        "\n",
        "                    for post in subreddit.search(query, limit=8, time_filter='month', sort='relevance'):\n",
        "                        if self._is_relevant_post(post, symbol_info):\n",
        "                            if post.title and len(post.title) > 20:\n",
        "                                texts.append(post.title)\n",
        "\n",
        "                            if hasattr(post, 'selftext') and post.selftext and len(post.selftext) > 30:\n",
        "                                texts.append(post.selftext[:600])\n",
        "\n",
        "                            # Get comments\n",
        "                            try:\n",
        "                                post.comments.replace_more(limit=0)\n",
        "                                for comment in post.comments[:3]:\n",
        "                                    if hasattr(comment, 'body') and len(comment.body) > 30:\n",
        "                                        if self._is_relevant_comment(comment.body, symbol_info):\n",
        "                                            texts.append(comment.body[:500])\n",
        "                            except:\n",
        "                                continue\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "        return self._analyze_texts(texts, \"Reddit\")\n",
        "\n",
        "    def get_news_sentiment(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get news sentiment analysis\"\"\"\n",
        "        print(f\"üîç Fetching News data for {symbol}...\")\n",
        "        texts = []\n",
        "        symbol_info = self._normalize_symbol(symbol)\n",
        "\n",
        "        # Try NewsAPI\n",
        "        if API_KEYS[\"NEWS_API_KEY\"]:\n",
        "            try:\n",
        "                url = \"https://newsapi.org/v2/everything\"\n",
        "\n",
        "                search_terms = [symbol_info['base_symbol']]\n",
        "                if symbol_info['company_name']:\n",
        "                    search_terms.append(f'\"{symbol_info[\"company_name\"]}\"')\n",
        "\n",
        "                query = ' OR '.join(search_terms)\n",
        "                if symbol_info['exchange'] in ['NSE', 'BSE']:\n",
        "                    query += ' AND (India OR NSE OR BSE OR stock)'\n",
        "                else:\n",
        "                    query += ' AND (stock OR financial OR earnings)'\n",
        "\n",
        "                params = {\n",
        "                    'q': query,\n",
        "                    'apiKey': API_KEYS[\"NEWS_API_KEY\"],\n",
        "                    'language': 'en',\n",
        "                    'sortBy': 'publishedAt',\n",
        "                    'pageSize': 30,\n",
        "                    'from': (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')\n",
        "                }\n",
        "\n",
        "                response = self.session.get(url, params=params)\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "                    for article in data.get('articles', []):\n",
        "                        title = article.get('title', '')\n",
        "                        description = article.get('description', '')\n",
        "                        content = article.get('content', '')\n",
        "\n",
        "                        full_text = f\"{title} {description} {content}\".strip()\n",
        "                        if len(full_text) > 30:\n",
        "                            texts.append(full_text[:800])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"NewsAPI error: {e}\")\n",
        "\n",
        "        # Fallback to demo data\n",
        "        if not texts:\n",
        "            company_name = symbol_info['company_name'] or symbol_info['base_symbol']\n",
        "            texts = [\n",
        "                f\"{company_name} reports strong quarterly earnings growth\",\n",
        "                f\"{symbol_info['base_symbol']} stock rallies on positive analyst coverage\",\n",
        "                f\"Institutional investors increase holdings in {company_name}\",\n",
        "                f\"Market volatility creates uncertainty for {symbol_info['base_symbol']} investors\",\n",
        "                f\"{company_name} management provides optimistic forward guidance\",\n",
        "                f\"Regulatory concerns weigh on {symbol_info['base_symbol']} performance\"\n",
        "            ]\n",
        "\n",
        "        return self._analyze_texts(texts, \"News\")\n",
        "\n",
        "    def get_youtube_sentiment(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get YouTube sentiment analysis\"\"\"\n",
        "        print(f\"üîç Fetching YouTube data for {symbol}...\")\n",
        "\n",
        "        symbol_info = self._normalize_symbol(symbol)\n",
        "\n",
        "        if not API_KEYS[\"YOUTUBE_API_KEY\"]:\n",
        "            company_name = symbol_info['company_name'] or symbol_info['base_symbol']\n",
        "            demo_texts = [\n",
        "                f\"{symbol_info['base_symbol']} Technical Analysis - Bullish breakout pattern emerging\",\n",
        "                f\"Why {company_name} is my top pick for 2024 - Strong fundamentals\",\n",
        "                f\"{symbol_info['base_symbol']} Stock Analysis: Buy or Sell? Complete review\",\n",
        "                f\"Great analysis! I'm adding {symbol_info['base_symbol']} to my portfolio\",\n",
        "                f\"Disagree with the {symbol_info['base_symbol']} valuation, seems overpriced\",\n",
        "                f\"{company_name} has excellent growth prospects, solid investment\",\n",
        "                f\"Thanks for the detailed {symbol_info['base_symbol']} breakdown!\"\n",
        "            ]\n",
        "            return self._analyze_texts(demo_texts, \"YouTube (Demo)\")\n",
        "\n",
        "        texts = []\n",
        "        try:\n",
        "            search_queries = [\n",
        "                f'\"{symbol_info[\"base_symbol\"]}\" stock analysis',\n",
        "                f'{symbol_info[\"company_name\"]} investment' if symbol_info['company_name'] else None\n",
        "            ]\n",
        "\n",
        "            search_queries = [q for q in search_queries if q]\n",
        "\n",
        "            for query in search_queries[:2]:\n",
        "                search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
        "                search_params = {\n",
        "                    'part': 'snippet',\n",
        "                    'q': query,\n",
        "                    'type': 'video',\n",
        "                    'maxResults': 15,\n",
        "                    'key': API_KEYS[\"YOUTUBE_API_KEY\"],\n",
        "                    'order': 'relevance'\n",
        "                }\n",
        "\n",
        "                response = self.session.get(search_url, params=search_params)\n",
        "                if response.status_code == 200:\n",
        "                    data = response.json()\n",
        "\n",
        "                    for item in data.get('items', []):\n",
        "                        snippet = item.get('snippet', {})\n",
        "                        title = snippet.get('title', '')\n",
        "                        description = snippet.get('description', '')\n",
        "\n",
        "                        if title and len(title) > 20:\n",
        "                            texts.append(title)\n",
        "                        if description and len(description) > 30:\n",
        "                            texts.append(description[:400])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"YouTube API error: {e}\")\n",
        "\n",
        "        return self._analyze_texts(texts, \"YouTube\")\n",
        "\n",
        "    def get_twitter_sentiment(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get Twitter sentiment analysis\"\"\"\n",
        "        print(f\"üîç Fetching Twitter data for {symbol}...\")\n",
        "\n",
        "        symbol_info = self._normalize_symbol(symbol)\n",
        "\n",
        "        if not API_KEYS[\"TWITTER_BEARER_TOKEN\"]:\n",
        "            demo_texts = [\n",
        "                f\"${symbol_info['base_symbol']} breaking resistance, bullish momentum building üìà\",\n",
        "                f\"Excellent earnings report from ${symbol_info['base_symbol']}, going long\",\n",
        "                f\"${symbol_info['base_symbol']} showing weakness, considering profit taking\",\n",
        "                f\"${symbol_info['base_symbol']} fundamentals remain strong despite market volatility\",\n",
        "                f\"Unusual volume in ${symbol_info['base_symbol']} suggests big move coming\",\n",
        "                f\"${symbol_info['base_symbol']} dividend yield attractive for income investors\",\n",
        "                f\"Love the ${symbol_info['base_symbol']} sector play, great positioning\"\n",
        "            ]\n",
        "            return self._analyze_texts(demo_texts, \"Twitter (Demo)\")\n",
        "\n",
        "        texts = []\n",
        "        try:\n",
        "            url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
        "            headers = {'Authorization': f'Bearer {API_KEYS[\"TWITTER_BEARER_TOKEN\"]}'}\n",
        "\n",
        "            search_terms = [f'${symbol_info[\"base_symbol\"]}', symbol_info['base_symbol']]\n",
        "            query = f'({\" OR \".join(search_terms)}) (stock OR investment OR earnings OR financial)'\n",
        "\n",
        "            if symbol_info['exchange'] in ['NSE', 'BSE']:\n",
        "                query += ' (India OR NSE OR BSE)'\n",
        "\n",
        "            query += ' -is:retweet lang:en'\n",
        "\n",
        "            params = {\n",
        "                'query': query,\n",
        "                'max_results': 100,\n",
        "                'tweet.fields': 'public_metrics,created_at'\n",
        "            }\n",
        "\n",
        "            response = self.session.get(url, headers=headers, params=params)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                for tweet in data.get('data', []):\n",
        "                    text = tweet.get('text', '')\n",
        "                    if text and len(text) > 25:\n",
        "                        texts.append(text)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Twitter API error: {e}\")\n",
        "\n",
        "        return self._analyze_texts(texts, \"Twitter\")\n",
        "\n",
        "    def _is_relevant_post(self, post, symbol_info: Dict) -> bool:\n",
        "        \"\"\"Check if a Reddit post is relevant to the stock\"\"\"\n",
        "        title_lower = post.title.lower()\n",
        "        selftext_lower = getattr(post, 'selftext', '').lower()\n",
        "        full_text = f\"{title_lower} {selftext_lower}\"\n",
        "\n",
        "        # Check for symbol mentions\n",
        "        if symbol_info['base_symbol'].lower() in full_text:\n",
        "            return True\n",
        "\n",
        "        # Check for company name mentions\n",
        "        if symbol_info['company_name']:\n",
        "            company_words = symbol_info['company_name'].lower().split()\n",
        "            if len(company_words) >= 2:\n",
        "                matches = sum(1 for word in company_words if word in full_text and len(word) > 3)\n",
        "                if matches >= 2:\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _is_relevant_comment(self, comment_text: str, symbol_info: Dict) -> bool:\n",
        "        \"\"\"Check if a comment is relevant to the stock\"\"\"\n",
        "        comment_lower = comment_text.lower()\n",
        "\n",
        "        if symbol_info['base_symbol'].lower() in comment_lower:\n",
        "            return True\n",
        "\n",
        "        if symbol_info['company_name']:\n",
        "            company_words = symbol_info['company_name'].lower().split()\n",
        "            for word in company_words:\n",
        "                if len(word) > 3 and word in comment_lower:\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _analyze_texts(self, texts: List[str], source: str) -> Dict:\n",
        "        \"\"\"Analyze texts using fine-tuned financial FinBERT\"\"\"\n",
        "        if not texts:\n",
        "            return self._empty_result()\n",
        "\n",
        "        valid_texts = []\n",
        "        for text in texts:\n",
        "            if text and isinstance(text, str) and len(text.strip()) > 15:\n",
        "                valid_texts.append(text.strip())\n",
        "\n",
        "        if not valid_texts:\n",
        "            return self._empty_result()\n",
        "\n",
        "        # Analyze with fine-tuned model\n",
        "        results = []\n",
        "        sentiments = []\n",
        "        confidences = []\n",
        "\n",
        "        print(f\"   üìä Analyzing {len(valid_texts)} texts with fine-tuned Financial FinBERT...\")\n",
        "\n",
        "        for text in valid_texts:\n",
        "            try:\n",
        "                result = self.sentiment_analyzer.predict_sentiment(text)\n",
        "                results.append(result)\n",
        "                sentiments.append(result['sentiment'])\n",
        "                confidences.append(result['confidence'])\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå Error analyzing text: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not sentiments:\n",
        "            return self._empty_result()\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_sentiment = np.mean(sentiments)\n",
        "        avg_confidence = np.mean(confidences)\n",
        "        sentiment_std = np.std(sentiments) if len(sentiments) > 1 else 0\n",
        "\n",
        "        # Determine overall label\n",
        "        if avg_sentiment > 0.2:\n",
        "            overall_label = \"POSITIVE\"\n",
        "        elif avg_sentiment < -0.2:\n",
        "            overall_label = \"NEGATIVE\"\n",
        "        else:\n",
        "            overall_label = \"NEUTRAL\"\n",
        "\n",
        "        return {\n",
        "            \"count\": len(valid_texts),\n",
        "            \"sentiment\": {\n",
        "                \"score\": round(avg_sentiment, 4),\n",
        "                \"confidence\": round(avg_confidence, 4),\n",
        "                \"std_dev\": round(sentiment_std, 4),\n",
        "                \"label\": overall_label\n",
        "            },\n",
        "            \"method\": \"fine_tuned_financial_finbert\",\n",
        "            \"distribution\": {\n",
        "                \"positive\": sum(1 for s in sentiments if s > 0.15),\n",
        "                \"negative\": sum(1 for s in sentiments if s < -0.15),\n",
        "                \"neutral\": sum(1 for s in sentiments if -0.15 <= s <= 0.15)\n",
        "            },\n",
        "            \"detailed_results\": results[:5]  # Store top 5 detailed results\n",
        "        }\n",
        "\n",
        "    def _empty_result(self) -> Dict:\n",
        "        \"\"\"Return empty result structure\"\"\"\n",
        "        return {\n",
        "            \"count\": 0,\n",
        "            \"sentiment\": {\n",
        "                \"score\": 0,\n",
        "                \"confidence\": 0,\n",
        "                \"std_dev\": 0,\n",
        "                \"label\": \"NEUTRAL\"\n",
        "            },\n",
        "            \"method\": \"no_data\",\n",
        "            \"distribution\": {\"positive\": 0, \"negative\": 0, \"neutral\": 0},\n",
        "            \"detailed_results\": []\n",
        "        }\n",
        "\n",
        "    def get_market_data(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get current market data for the stock\"\"\"\n",
        "        print(f\"üìà Fetching market data for {symbol}...\")\n",
        "\n",
        "        if not HAS_YFINANCE:\n",
        "            print(\"‚ùå yfinance not available - using demo market data\")\n",
        "            return {\n",
        "                \"current_price\": 150.25,\n",
        "                \"change\": 2.35,\n",
        "                \"change_percent\": 1.59,\n",
        "                \"volume\": 1250000,\n",
        "                \"market_cap\": \"15.2B\",\n",
        "                \"pe_ratio\": 18.5,\n",
        "                \"beta\": 1.15,\n",
        "                \"52_week_high\": 180.50,\n",
        "                \"52_week_low\": 120.30,\n",
        "                \"status\": \"demo\"\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            info = ticker.info\n",
        "            hist = ticker.history(period=\"2d\")\n",
        "\n",
        "            if len(hist) < 1:\n",
        "                return {\"status\": \"no_data\"}\n",
        "\n",
        "            current_price = hist['Close'].iloc[-1] if len(hist) > 0 else 0\n",
        "            prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price\n",
        "\n",
        "            change = current_price - prev_close\n",
        "            change_percent = (change / prev_close * 100) if prev_close != 0 else 0\n",
        "\n",
        "            return {\n",
        "                \"current_price\": round(current_price, 2),\n",
        "                \"change\": round(change, 2),\n",
        "                \"change_percent\": round(change_percent, 2),\n",
        "                \"volume\": int(hist['Volume'].iloc[-1]) if len(hist) > 0 else 0,\n",
        "                \"market_cap\": info.get('marketCap', 'N/A'),\n",
        "                \"pe_ratio\": info.get('trailingPE', 'N/A'),\n",
        "                \"beta\": info.get('beta', 'N/A'),\n",
        "                \"52_week_high\": info.get('fiftyTwoWeekHigh', 'N/A'),\n",
        "                \"52_week_low\": info.get('fiftyTwoWeekLow', 'N/A'),\n",
        "                \"status\": \"success\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error fetching market data: {e}\")\n",
        "            return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "class FinancialSentimentAnalyzer:\n",
        "    \"\"\"Main financial sentiment analysis system\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"./finbert_financial_sentiment\"):\n",
        "        self.data_collector = FinancialDataCollector(model_path)\n",
        "        self.model_path = model_path\n",
        "\n",
        "    def _display_model_status(self):\n",
        "        \"\"\"Display current model status\"\"\"\n",
        "        print(f\"\\nü§ñ MODEL STATUS:\")\n",
        "        if self.data_collector.sentiment_analyzer.model:\n",
        "            print(f\"   ‚úÖ Fine-tuned Financial FinBERT: LOADED\")\n",
        "            print(f\"   üìä Training Accuracy: {self.data_collector.sentiment_analyzer.training_accuracy}\")\n",
        "            print(f\"   üîß Device: {self.data_collector.sentiment_analyzer.device}\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Fine-tuned Financial FinBERT: NOT AVAILABLE\")\n",
        "            print(f\"   üîÑ Using enhanced fallback sentiment analysis\")\n",
        "\n",
        "    def analyze_stock(self, symbol: str) -> Dict:\n",
        "        \"\"\"Comprehensive financial sentiment analysis\"\"\"\n",
        "        print(f\"üöÄ FINANCIAL SENTIMENT ANALYSIS - FINE-TUNED FINBERT\")\n",
        "        print(f\"üìä Analyzing: {symbol}\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        self._display_model_status()\n",
        "\n",
        "        # Data sources\n",
        "        sources = {\n",
        "            \"Reddit\": self.data_collector.get_reddit_sentiment,\n",
        "            \"News\": self.data_collector.get_news_sentiment,\n",
        "            \"YouTube\": self.data_collector.get_youtube_sentiment,\n",
        "            \"Twitter\": self.data_collector.get_twitter_sentiment,\n",
        "        }\n",
        "\n",
        "        sources_data = {}\n",
        "        all_scores = []\n",
        "        all_confidences = []\n",
        "        total_samples = 0\n",
        "\n",
        "        # Analyze each source\n",
        "        for source_name, source_func in sources.items():\n",
        "            try:\n",
        "                print(f\"\\n‚è≥ Processing {source_name}...\")\n",
        "                data = source_func(symbol)\n",
        "                sources_data[source_name] = data\n",
        "\n",
        "                if data[\"count\"] > 0:\n",
        "                    all_scores.append(data[\"sentiment\"][\"score\"])\n",
        "                    all_confidences.append(data[\"sentiment\"][\"confidence\"])\n",
        "                    total_samples += data[\"count\"]\n",
        "\n",
        "                time.sleep(0.5)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error with {source_name}: {e}\")\n",
        "                sources_data[source_name] = self.data_collector._empty_result()\n",
        "\n",
        "        # Get market data\n",
        "        print(f\"\\nüìà Fetching market data for {symbol}...\")\n",
        "        market_data = self.data_collector.get_market_data(symbol)\n",
        "\n",
        "        # Calculate overall sentiment\n",
        "        if all_scores:\n",
        "            overall_sentiment = np.mean(all_scores)\n",
        "            overall_confidence = np.mean(all_confidences)\n",
        "            sentiment_std = np.std(all_scores)\n",
        "\n",
        "            # Weight by sample size\n",
        "            weighted_scores = []\n",
        "            total_weight = 0\n",
        "            for source_name, data in sources_data.items():\n",
        "                if data[\"count\"] > 0:\n",
        "                    weight = data[\"count\"]\n",
        "                    weighted_scores.extend([data[\"sentiment\"][\"score\"]] * weight)\n",
        "                    total_weight += weight\n",
        "\n",
        "            weighted_sentiment = np.mean(weighted_scores) if weighted_scores else 0\n",
        "\n",
        "            # Determine overall label\n",
        "            if weighted_sentiment > 0.2:\n",
        "                overall_label = \"POSITIVE\"\n",
        "                emoji = \"üìà\"\n",
        "            elif weighted_sentiment < -0.2:\n",
        "                overall_label = \"NEGATIVE\"\n",
        "                emoji = \"üìâ\"\n",
        "            else:\n",
        "                overall_label = \"NEUTRAL\"\n",
        "                emoji = \"‚û°Ô∏è\"\n",
        "        else:\n",
        "            overall_sentiment = 0\n",
        "            overall_confidence = 0\n",
        "            sentiment_std = 0\n",
        "            weighted_sentiment = 0\n",
        "            overall_label = \"NEUTRAL\"\n",
        "            emoji = \"‚ùì\"\n",
        "\n",
        "        # Compile results\n",
        "        results = {\n",
        "            \"symbol\": symbol,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"model_info\": {\n",
        "                \"type\": \"fine_tuned_financial_finbert\",\n",
        "                \"path\": self.model_path,\n",
        "                \"training_accuracy\": self.data_collector.sentiment_analyzer.training_accuracy,\n",
        "                \"device\": str(self.data_collector.sentiment_analyzer.device) if self.data_collector.sentiment_analyzer.device else \"CPU\"\n",
        "            },\n",
        "            \"overall_sentiment\": {\n",
        "                \"score\": round(weighted_sentiment, 4),\n",
        "                \"confidence\": round(overall_confidence, 4),\n",
        "                \"label\": overall_label,\n",
        "                \"emoji\": emoji,\n",
        "                \"std_dev\": round(sentiment_std, 4)\n",
        "            },\n",
        "            \"market_data\": market_data,\n",
        "            \"sources\": sources_data,\n",
        "            \"summary\": {\n",
        "                \"total_samples\": total_samples,\n",
        "                \"sources_analyzed\": len([s for s in sources_data.values() if s[\"count\"] > 0]),\n",
        "                \"analysis_method\": \"fine_tuned_financial_finbert\" if self.data_collector.sentiment_analyzer.model else \"enhanced_fallback\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self._display_results(results)\n",
        "        return results\n",
        "\n",
        "    def _display_results(self, results: Dict):\n",
        "        \"\"\"Display formatted analysis results\"\"\"\n",
        "        print(f\"\\nüéØ ANALYSIS RESULTS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Overall sentiment\n",
        "        overall = results[\"overall_sentiment\"]\n",
        "        print(f\"üìä OVERALL SENTIMENT: {overall['emoji']} {overall['label']}\")\n",
        "        print(f\"   Score: {overall['score']:.4f} (Range: -1.0 to +1.0)\")\n",
        "        print(f\"   Confidence: {overall['confidence']:.2%}\")\n",
        "        print(f\"   Standard Deviation: {overall['std_dev']:.4f}\")\n",
        "\n",
        "        # Market data\n",
        "        if results[\"market_data\"].get(\"status\") == \"success\":\n",
        "            market = results[\"market_data\"]\n",
        "            change_emoji = \"üìà\" if market[\"change\"] > 0 else \"üìâ\" if market[\"change\"] < 0 else \"‚û°Ô∏è\"\n",
        "            print(f\"\\nüí∞ MARKET DATA:\")\n",
        "            print(f\"   Price: ${market['current_price']:.2f} {change_emoji}\")\n",
        "            print(f\"   Change: {market['change']:+.2f} ({market['change_percent']:+.2f}%)\")\n",
        "            print(f\"   Volume: {market['volume']:,}\")\n",
        "            if market['pe_ratio'] != 'N/A':\n",
        "                print(f\"   P/E Ratio: {market['pe_ratio']:.2f}\")\n",
        "\n",
        "        # Source breakdown\n",
        "        print(f\"\\nüì± SOURCE BREAKDOWN:\")\n",
        "        for source_name, data in results[\"sources\"].items():\n",
        "            if data[\"count\"] > 0:\n",
        "                sentiment = data[\"sentiment\"]\n",
        "                emoji = \"üìà\" if sentiment[\"score\"] > 0.1 else \"üìâ\" if sentiment[\"score\"] < -0.1 else \"‚û°Ô∏è\"\n",
        "                print(f\"   {source_name}: {emoji} {sentiment['label']} \"\n",
        "                      f\"({sentiment['score']:+.3f}, {data['count']} samples)\")\n",
        "            else:\n",
        "                print(f\"   {source_name}: ‚ùå No data\")\n",
        "\n",
        "        # Distribution\n",
        "        print(f\"\\nüìà SENTIMENT DISTRIBUTION:\")\n",
        "        total_classified = 0\n",
        "        for source_name, data in results[\"sources\"].items():\n",
        "            if data[\"count\"] > 0:\n",
        "                dist = data[\"distribution\"]\n",
        "                total_classified += sum(dist.values())\n",
        "\n",
        "        if total_classified > 0:\n",
        "            total_pos = sum(data[\"distribution\"][\"positive\"] for data in results[\"sources\"].values())\n",
        "            total_neg = sum(data[\"distribution\"][\"negative\"] for data in results[\"sources\"].values())\n",
        "            total_neu = sum(data[\"distribution\"][\"neutral\"] for data in results[\"sources\"].values())\n",
        "\n",
        "            print(f\"   Positive: {total_pos} ({total_pos/total_classified*100:.1f}%)\")\n",
        "            print(f\"   Negative: {total_neg} ({total_neg/total_classified*100:.1f}%)\")\n",
        "            print(f\"   Neutral:  {total_neu} ({total_neu/total_classified*100:.1f}%)\")\n",
        "\n",
        "        # Summary\n",
        "        print(f\"\\nüìã SUMMARY:\")\n",
        "        print(f\"   Total Samples Analyzed: {results['summary']['total_samples']}\")\n",
        "        print(f\"   Active Sources: {results['summary']['sources_analyzed']}/4\")\n",
        "        print(f\"   Analysis Method: {results['summary']['analysis_method']}\")\n",
        "        print(f\"   Model Training Accuracy: {results['model_info']['training_accuracy']}\")\n",
        "\n",
        "        # Investment recommendation\n",
        "        self._display_recommendation(results)\n",
        "\n",
        "    def _display_recommendation(self, results: Dict):\n",
        "        \"\"\"Display investment recommendation based on sentiment analysis\"\"\"\n",
        "        print(f\"\\nüí° INVESTMENT INSIGHTS:\")\n",
        "\n",
        "        overall_score = results[\"overall_sentiment\"][\"score\"]\n",
        "        confidence = results[\"overall_sentiment\"][\"confidence\"]\n",
        "        total_samples = results[\"summary\"][\"total_samples\"]\n",
        "\n",
        "        # Generate recommendation\n",
        "        if total_samples < 10:\n",
        "            recommendation = \"‚ö†Ô∏è LIMITED DATA - Insufficient samples for reliable analysis\"\n",
        "            risk_level = \"HIGH\"\n",
        "        elif confidence < 0.6:\n",
        "            recommendation = \"‚ö†Ô∏è LOW CONFIDENCE - Mixed or unclear sentiment signals\"\n",
        "            risk_level = \"MEDIUM-HIGH\"\n",
        "        elif overall_score > 0.3 and confidence > 0.7:\n",
        "            recommendation = \"üü¢ POSITIVE OUTLOOK - Strong bullish sentiment detected\"\n",
        "            risk_level = \"LOW-MEDIUM\"\n",
        "        elif overall_score < -0.3 and confidence > 0.7:\n",
        "            recommendation = \"üî¥ NEGATIVE OUTLOOK - Strong bearish sentiment detected\"\n",
        "            risk_level = \"MEDIUM-HIGH\"\n",
        "        elif -0.1 <= overall_score <= 0.1:\n",
        "            recommendation = \"üü° NEUTRAL STANCE - Mixed sentiment, wait for clearer signals\"\n",
        "            risk_level = \"MEDIUM\"\n",
        "        elif overall_score > 0.1:\n",
        "            recommendation = \"üü¢ CAUTIOUSLY POSITIVE - Moderate bullish sentiment\"\n",
        "            risk_level = \"MEDIUM\"\n",
        "        else:\n",
        "            recommendation = \"üü° CAUTIOUSLY NEGATIVE - Moderate bearish sentiment\"\n",
        "            risk_level = \"MEDIUM\"\n",
        "\n",
        "        print(f\"   {recommendation}\")\n",
        "        print(f\"   Risk Level: {risk_level}\")\n",
        "\n",
        "        # Additional insights\n",
        "        if results[\"market_data\"].get(\"status\") == \"success\":\n",
        "            market = results[\"market_data\"]\n",
        "            if market[\"change_percent\"] > 5:\n",
        "                print(f\"   üìà Strong positive price movement ({market['change_percent']:+.2f}%)\")\n",
        "            elif market[\"change_percent\"] < -5:\n",
        "                print(f\"   üìâ Strong negative price movement ({market['change_percent']:+.2f}%)\")\n",
        "\n",
        "        print(f\"\\n‚ö†Ô∏è  DISCLAIMER: This analysis is for informational purposes only.\")\n",
        "        print(f\"   Always conduct your own research and consult financial advisors.\")\n",
        "\n",
        "    def batch_analyze(self, symbols: List[str]) -> Dict:\n",
        "        \"\"\"Analyze multiple stocks and compare sentiment\"\"\"\n",
        "        print(f\"üîÑ BATCH ANALYSIS - {len(symbols)} SYMBOLS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        batch_results = {}\n",
        "        sentiment_summary = []\n",
        "\n",
        "        for i, symbol in enumerate(symbols, 1):\n",
        "            print(f\"\\nüìä [{i}/{len(symbols)}] Analyzing {symbol}...\")\n",
        "            try:\n",
        "                result = self.analyze_stock(symbol)\n",
        "                batch_results[symbol] = result\n",
        "\n",
        "                sentiment_summary.append({\n",
        "                    \"symbol\": symbol,\n",
        "                    \"sentiment_score\": result[\"overall_sentiment\"][\"score\"],\n",
        "                    \"label\": result[\"overall_sentiment\"][\"label\"],\n",
        "                    \"confidence\": result[\"overall_sentiment\"][\"confidence\"],\n",
        "                    \"total_samples\": result[\"summary\"][\"total_samples\"]\n",
        "                })\n",
        "\n",
        "                time.sleep(1)  # Rate limiting\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error analyzing {symbol}: {e}\")\n",
        "                batch_results[symbol] = {\"error\": str(e)}\n",
        "\n",
        "        # Sort by sentiment score\n",
        "        sentiment_summary.sort(key=lambda x: x[\"sentiment_score\"], reverse=True)\n",
        "\n",
        "        print(f\"\\nüèÜ BATCH RESULTS RANKING:\")\n",
        "        print(\"=\" * 70)\n",
        "        for i, item in enumerate(sentiment_summary, 1):\n",
        "            emoji = \"üìà\" if item[\"sentiment_score\"] > 0.1 else \"üìâ\" if item[\"sentiment_score\"] < -0.1 else \"‚û°Ô∏è\"\n",
        "            print(f\"{i:2d}. {item['symbol']:8s} {emoji} {item['label']:8s} \"\n",
        "                  f\"({item['sentiment_score']:+.3f}, {item['total_samples']} samples)\")\n",
        "\n",
        "        return {\n",
        "            \"batch_results\": batch_results,\n",
        "            \"ranking\": sentiment_summary,\n",
        "            \"analysis_timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function with examples\"\"\"\n",
        "    print(\"üöÄ FINANCIAL SENTIMENT ANALYSIS SYSTEM\")\n",
        "    print(\"ü§ñ Powered by Fine-tuned FinBERT for Financial Data\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = FinancialSentimentAnalyzer()\n",
        "\n",
        "    # Example usage\n",
        "    print(\"\\nüìã EXAMPLE USAGE:\")\n",
        "    print(\"1. Single stock analysis:\")\n",
        "    print(\"   analyzer.analyze_stock('AAPL')\")\n",
        "    print(\"   analyzer.analyze_stock('RELIANCE.NS')  # Indian stock\")\n",
        "    print(\"\\n2. Batch analysis:\")\n",
        "    print(\"   analyzer.batch_analyze(['AAPL', 'GOOGL', 'MSFT'])\")\n",
        "    print(\"\\n3. Custom analysis:\")\n",
        "    print(\"   result = analyzer.analyze_stock('TSLA')\")\n",
        "    print(\"   print(result['overall_sentiment'])\")\n",
        "\n",
        "    # Interactive mode\n",
        "    while True:\n",
        "        print(f\"\\n\" + \"=\" * 70)\n",
        "        print(\"üîç INTERACTIVE ANALYSIS MODE\")\n",
        "        choice = input(\"\\n1. Single Stock Analysis\\n2. Batch Analysis\\n3. Exit\\nEnter choice (1-3): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            symbol = input(\"Enter stock symbol (e.g., AAPL, RELIANCE.NS): \").strip().upper()\n",
        "            if symbol:\n",
        "                try:\n",
        "                    analyzer.analyze_stock(symbol)\n",
        "                except KeyboardInterrupt:\n",
        "                    print(\"\\n‚èπÔ∏è Analysis interrupted by user\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "        elif choice == '2':\n",
        "            symbols_input = input(\"Enter stock symbols separated by commas (e.g., AAPL,GOOGL,MSFT): \").strip()\n",
        "            if symbols_input:\n",
        "                symbols = [s.strip().upper() for s in symbols_input.split(',') if s.strip()]\n",
        "                if symbols:\n",
        "                    try:\n",
        "                        analyzer.batch_analyze(symbols)\n",
        "                    except KeyboardInterrupt:\n",
        "                        print(\"\\n‚èπÔ∏è Batch analysis interrupted by user\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "        elif choice == '3':\n",
        "            print(\"üëã Thank you for using Financial Sentiment Analysis!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Invalid choice. Please enter 1, 2, or 3.\")\n",
        "\n",
        "# Advanced usage examples\n",
        "def advanced_examples():\n",
        "    \"\"\"Advanced usage examples and features\"\"\"\n",
        "    analyzer = FinancialSentimentAnalyzer()\n",
        "\n",
        "    print(\"üî¨ ADVANCED USAGE EXAMPLES\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Example 1: Tech stocks comparison\n",
        "    print(\"\\nüì± Tech Stocks Sentiment Comparison:\")\n",
        "    tech_stocks = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
        "    tech_results = analyzer.batch_analyze(tech_stocks)\n",
        "\n",
        "    # Example 2: Sector analysis\n",
        "    print(\"\\nüè≠ Sector Analysis Example:\")\n",
        "    financial_stocks = ['JPM', 'BAC', 'WFC', 'C']\n",
        "    financial_results = analyzer.batch_analyze(financial_stocks)\n",
        "\n",
        "    # Example 3: Indian stocks\n",
        "    print(\"\\nüáÆüá≥ Indian Stocks Analysis:\")\n",
        "    indian_stocks = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS']\n",
        "    indian_results = analyzer.batch_analyze(indian_stocks)\n",
        "\n",
        "    return {\n",
        "        \"tech_analysis\": tech_results,\n",
        "        \"financial_analysis\": financial_results,\n",
        "        \"indian_analysis\": indian_results\n",
        "    }\n",
        "\n",
        "def export_results(results: Dict, filename: str = None):\n",
        "    \"\"\"Export analysis results to JSON file\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"sentiment_analysis_{timestamp}.json\"\n",
        "\n",
        "    try:\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(results, f, indent=2, default=str)\n",
        "        print(f\"üìÅ Results exported to: {filename}\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error exporting results: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_results(filename: str) -> Optional[Dict]:\n",
        "    \"\"\"Load previously saved analysis results\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            results = json.load(f)\n",
        "        print(f\"üìÅ Results loaded from: {filename}\")\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading results: {e}\")\n",
        "        return None\n",
        "\n",
        "# Utility functions\n",
        "def get_trending_stocks() -> List[str]:\n",
        "    \"\"\"Get list of trending stocks (demo implementation)\"\"\"\n",
        "    # In a real implementation, this could fetch from:\n",
        "    # - Yahoo Finance trending\n",
        "    # - Reddit WallStreetBets mentions\n",
        "    # - Google Trends for stocks\n",
        "    # - Financial news APIs\n",
        "\n",
        "    trending = [\n",
        "        'AAPL', 'TSLA', 'GOOGL', 'MSFT', 'AMZN', 'NVDA', 'META', 'NFLX',\n",
        "        'AMD', 'BABA', 'PLTR', 'GME', 'AMC', 'SPCE', 'COIN', 'HOOD'\n",
        "    ]\n",
        "\n",
        "    print(f\"üìà Sample trending stocks: {', '.join(trending[:8])}...\")\n",
        "    return trending\n",
        "\n",
        "def sentiment_to_trading_signal(sentiment_score: float, confidence: float) -> str:\n",
        "    \"\"\"Convert sentiment analysis to trading signal\"\"\"\n",
        "    if confidence < 0.6:\n",
        "        return \"HOLD - Low confidence\"\n",
        "\n",
        "    if sentiment_score > 0.4:\n",
        "        return \"STRONG BUY\"\n",
        "    elif sentiment_score > 0.2:\n",
        "        return \"BUY\"\n",
        "    elif sentiment_score > 0.05:\n",
        "        return \"WEAK BUY\"\n",
        "    elif sentiment_score > -0.05:\n",
        "        return \"HOLD\"\n",
        "    elif sentiment_score > -0.2:\n",
        "        return \"WEAK SELL\"\n",
        "    elif sentiment_score > -0.4:\n",
        "        return \"SELL\"\n",
        "    else:\n",
        "        return \"STRONG SELL\"\n",
        "\n",
        "# Performance monitoring\n",
        "def benchmark_model_performance():\n",
        "    \"\"\"Benchmark the fine-tuned model performance\"\"\"\n",
        "    analyzer = FinancialSentimentAnalyzer()\n",
        "\n",
        "    # Test with known sentiment examples\n",
        "    test_cases = [\n",
        "        (\"AAPL quarterly earnings beat expectations significantly\", \"positive\"),\n",
        "        (\"Tesla stock crashes on disappointing delivery numbers\", \"negative\"),\n",
        "        (\"Microsoft maintains steady growth trajectory\", \"neutral\"),\n",
        "        (\"Amazon Prime Day sales surge drives revenue growth\", \"positive\"),\n",
        "        (\"Google faces regulatory challenges in Europe\", \"negative\")\n",
        "    ]\n",
        "\n",
        "    print(\"üß™ MODEL PERFORMANCE BENCHMARK\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    correct_predictions = 0\n",
        "    for text, expected in test_cases:\n",
        "        result = analyzer.data_collector.sentiment_analyzer.predict_sentiment(text)\n",
        "        predicted = result[\"label\"].lower()\n",
        "\n",
        "        is_correct = predicted == expected\n",
        "        if is_correct:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        emoji = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
        "        print(f\"{emoji} Expected: {expected:8s} | Predicted: {predicted:8s} | Score: {result['sentiment']:+.3f}\")\n",
        "\n",
        "    accuracy = correct_predictions / len(test_cases) * 100\n",
        "    print(f\"\\nüìä Benchmark Accuracy: {accuracy:.1f}% ({correct_predictions}/{len(test_cases)})\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run main interactive mode\n",
        "        main()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nüëã Program terminated by user. Goodbye!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Unexpected error: {e}\")\n",
        "        print(\"Please check your configuration and try again.\")\n",
        "\n",
        "# Additional helper functions for advanced users\n",
        "class SentimentTracker:\n",
        "    \"\"\"Track sentiment changes over time\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"./finbert_financial_sentiment\"):\n",
        "        self.analyzer = FinancialSentimentAnalyzer(model_path)\n",
        "        self.history = {}\n",
        "\n",
        "    def track_symbol(self, symbol: str, interval_hours: int = 24):\n",
        "        \"\"\"Track sentiment for a symbol over time\"\"\"\n",
        "        if symbol not in self.history:\n",
        "            self.history[symbol] = []\n",
        "\n",
        "        result = self.analyzer.analyze_stock(symbol)\n",
        "\n",
        "        self.history[symbol].append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"sentiment_score\": result[\"overall_sentiment\"][\"score\"],\n",
        "            \"confidence\": result[\"overall_sentiment\"][\"confidence\"],\n",
        "            \"total_samples\": result[\"summary\"][\"total_samples\"]\n",
        "        })\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_sentiment_trend(self, symbol: str) -> Dict:\n",
        "        \"\"\"Get sentiment trend analysis for a symbol\"\"\"\n",
        "        if symbol not in self.history or len(self.history[symbol]) < 2:\n",
        "            return {\"status\": \"insufficient_data\"}\n",
        "\n",
        "        history = self.history[symbol]\n",
        "        latest = history[-1]\n",
        "        previous = history[-2]\n",
        "\n",
        "        sentiment_change = latest[\"sentiment_score\"] - previous[\"sentiment_score\"]\n",
        "\n",
        "        if sentiment_change > 0.1:\n",
        "            trend = \"IMPROVING\"\n",
        "            trend_emoji = \"üìà\"\n",
        "        elif sentiment_change < -0.1:\n",
        "            trend = \"DECLINING\"\n",
        "            trend_emoji = \"üìâ\"\n",
        "        else:\n",
        "            trend = \"STABLE\"\n",
        "            trend_emoji = \"‚û°Ô∏è\"\n",
        "\n",
        "        return {\n",
        "            \"symbol\": symbol,\n",
        "            \"trend\": trend,\n",
        "            \"trend_emoji\": trend_emoji,\n",
        "            \"sentiment_change\": round(sentiment_change, 4),\n",
        "            \"current_sentiment\": latest[\"sentiment_score\"],\n",
        "            \"current_confidence\": latest[\"confidence\"],\n",
        "            \"data_points\": len(history)\n",
        "        }\n",
        "\n",
        "# Usage examples for different scenarios\n",
        "def demo_usage():\n",
        "    \"\"\"Demonstrate various usage scenarios\"\"\"\n",
        "    print(\"üé¨ DEMONSTRATION MODE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    analyzer = FinancialSentimentAnalyzer()\n",
        "\n",
        "    # Scenario 1: Pre-earnings analysis\n",
        "    print(\"\\nüìä Scenario 1: Pre-earnings sentiment check\")\n",
        "    result = analyzer.analyze_stock(\"AAPL\")\n",
        "\n",
        "    # Scenario 2: Portfolio sentiment overview\n",
        "    print(\"\\nüíº Scenario 2: Portfolio sentiment overview\")\n",
        "    portfolio = ['AAPL', 'GOOGL', 'MSFT', 'AMZN']\n",
        "    batch_result = analyzer.batch_analyze(portfolio)\n",
        "\n",
        "    # Scenario 3: Sector comparison\n",
        "    print(\"\\nüè≠ Scenario 3: Sector sentiment comparison\")\n",
        "    banking_stocks = ['JPM', 'BAC', 'WFC']\n",
        "    banking_result = analyzer.batch_analyze(banking_stocks)\n",
        "\n",
        "    return {\n",
        "        \"single_analysis\": result,\n",
        "        \"portfolio_analysis\": batch_result,\n",
        "        \"sector_analysis\": banking_result\n",
        "    }\n",
        "\n",
        "# Configuration and setup helper\n",
        "def setup_api_keys():\n",
        "    \"\"\"Guide users through API key setup\"\"\"\n",
        "    print(\"üîß API KEY SETUP GUIDE\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"For full functionality, set up these optional API keys:\")\n",
        "    print(\"1. Reddit API: reddit_client_id, reddit_client_secret\")\n",
        "    print(\"2. News API: news_api\")\n",
        "    print(\"3. YouTube API: YOUTUBE_API_KEY\")\n",
        "    print(\"4. Twitter API: twitter_api\")\n",
        "    print(\"\\nSet as environment variables or in Google Colab secrets.\")\n",
        "    print(\"The system will work with demo data if APIs are not available.\")\n",
        "\n",
        "# Export the main classes for external use\n",
        "__all__ = [\n",
        "    'FinancialSentimentAnalyzer',\n",
        "    'FinancialFinBERTAnalyzer',\n",
        "    'FinancialDataCollector',\n",
        "    'SentimentTracker',\n",
        "    'export_results',\n",
        "    'load_results',\n",
        "    'sentiment_to_trading_signal',\n",
        "    'benchmark_model_performance'\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6vfEVlP5AC7",
        "outputId": "24ac3310-6ff7-463a-9896-3ddcc76dfabf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ FINANCIAL SENTIMENT ANALYSIS SYSTEM\n",
            "ü§ñ Powered by Fine-tuned FinBERT for Financial Data\n",
            "======================================================================\n",
            "üöÄ Initializing Financial Fine-tuned FinBERT model...\n",
            "üìç Model path: ./finbert_financial_sentiment\n",
            "üîß Using device: cuda\n",
            "üì• Loading tokenizer...\n",
            "üì• Loading fine-tuned financial model...\n",
            "üìä Model training accuracy: 0.9436\n",
            "‚úÖ Financial Fine-tuned FinBERT model loaded successfully!\n",
            "‚úÖ Reddit client initialized\n",
            "\n",
            "üìã EXAMPLE USAGE:\n",
            "1. Single stock analysis:\n",
            "   analyzer.analyze_stock('AAPL')\n",
            "   analyzer.analyze_stock('RELIANCE.NS')  # Indian stock\n",
            "\n",
            "2. Batch analysis:\n",
            "   analyzer.batch_analyze(['AAPL', 'GOOGL', 'MSFT'])\n",
            "\n",
            "3. Custom analysis:\n",
            "   result = analyzer.analyze_stock('TSLA')\n",
            "   print(result['overall_sentiment'])\n",
            "\n",
            "======================================================================\n",
            "üîç INTERACTIVE ANALYSIS MODE\n",
            "\n",
            "1. Single Stock Analysis\n",
            "2. Batch Analysis\n",
            "3. Exit\n",
            "Enter choice (1-3): 1\n",
            "Enter stock symbol (e.g., AAPL, RELIANCE.NS): TATAMOTORS.NS\n",
            "üöÄ FINANCIAL SENTIMENT ANALYSIS - FINE-TUNED FINBERT\n",
            "üìä Analyzing: TATAMOTORS.NS\n",
            "======================================================================\n",
            "\n",
            "ü§ñ MODEL STATUS:\n",
            "   ‚úÖ Fine-tuned Financial FinBERT: LOADED\n",
            "   üìä Training Accuracy: 0.9436\n",
            "   üîß Device: cuda\n",
            "\n",
            "‚è≥ Processing Reddit...\n",
            "üîç Fetching Reddit data for TATAMOTORS.NS...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üìã Company: Tata Motors\n",
            "   üè¢ Sector: Consumer Cyclical\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üìä Analyzing 9 texts with fine-tuned Financial FinBERT...\n",
            "\n",
            "‚è≥ Processing News...\n",
            "üîç Fetching News data for TATAMOTORS.NS...\n",
            "   üìã Company: Tata Motors\n",
            "   üè¢ Sector: Consumer Cyclical\n",
            "   üìä Analyzing 30 texts with fine-tuned Financial FinBERT...\n",
            "\n",
            "‚è≥ Processing YouTube...\n",
            "üîç Fetching YouTube data for TATAMOTORS.NS...\n",
            "   üìã Company: Tata Motors\n",
            "   üè¢ Sector: Consumer Cyclical\n",
            "   üìä Analyzing 58 texts with fine-tuned Financial FinBERT...\n",
            "\n",
            "‚è≥ Processing Twitter...\n",
            "üîç Fetching Twitter data for TATAMOTORS.NS...\n",
            "   üìã Company: Tata Motors\n",
            "   üè¢ Sector: Consumer Cyclical\n",
            "\n",
            "üìà Fetching market data for TATAMOTORS.NS...\n",
            "üìà Fetching market data for TATAMOTORS.NS...\n",
            "\n",
            "üéØ ANALYSIS RESULTS\n",
            "======================================================================\n",
            "üìä OVERALL SENTIMENT: ‚û°Ô∏è NEUTRAL\n",
            "   Score: 0.0663 (Range: -1.0 to +1.0)\n",
            "   Confidence: 89.06%\n",
            "   Standard Deviation: 0.0553\n",
            "\n",
            "üí∞ MARKET DATA:\n",
            "   Price: $648.85 üìâ\n",
            "   Change: -17.10 (-2.57%)\n",
            "   Volume: 12,546,169\n",
            "   P/E Ratio: 9.99\n",
            "\n",
            "üì± SOURCE BREAKDOWN:\n",
            "   Reddit: ‚û°Ô∏è NEUTRAL (+0.011, 9 samples)\n",
            "   News: üìà NEUTRAL (+0.139, 30 samples)\n",
            "   YouTube: ‚û°Ô∏è NEUTRAL (+0.037, 58 samples)\n",
            "   Twitter: ‚ùå No data\n",
            "\n",
            "üìà SENTIMENT DISTRIBUTION:\n",
            "   Positive: 22 (22.7%)\n",
            "   Negative: 13 (13.4%)\n",
            "   Neutral:  62 (63.9%)\n",
            "\n",
            "üìã SUMMARY:\n",
            "   Total Samples Analyzed: 97\n",
            "   Active Sources: 3/4\n",
            "   Analysis Method: fine_tuned_financial_finbert\n",
            "   Model Training Accuracy: 0.9436\n",
            "\n",
            "üí° INVESTMENT INSIGHTS:\n",
            "   üü° NEUTRAL STANCE - Mixed sentiment, wait for clearer signals\n",
            "   Risk Level: MEDIUM\n",
            "\n",
            "‚ö†Ô∏è  DISCLAIMER: This analysis is for informational purposes only.\n",
            "   Always conduct your own research and consult financial advisors.\n",
            "\n",
            "======================================================================\n",
            "üîç INTERACTIVE ANALYSIS MODE\n",
            "\n",
            "\n",
            "üëã Program terminated by user. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}